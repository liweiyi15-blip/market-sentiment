import time
import requests
import os
import pytz
import holidays
import pandas as pd
import yfinance as yf
import io
import json
import warnings
import re
import shutil 
import matplotlib
# âš ï¸ã€ä¼˜åŒ–ç‚¹1ã€‘å¼ºåˆ¶ä½¿ç”¨éäº¤äº’å¼åç«¯ï¼Œå¤§å¹…èŠ‚çœå†…å­˜
matplotlib.use('Agg') 
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
# âš ï¸ã€ä¼˜åŒ–ç‚¹2ã€‘å¼•å…¥åƒåœ¾å›æ”¶æœºåˆ¶
import gc 
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By

# ==========================================
# âš™ï¸ å…¨å±€é…ç½®åŒº
# ==========================================

WEBHOOK_URL = os.getenv("WEBHOOK_URL") 

# ------------------------------------------
# â° æ—¶é—´è¡¨ (ç¾ä¸œæ—¶é—´ ET)
# ------------------------------------------

# 1. FedWatch (ç¾è”å‚¨è§‚å¯Ÿ) æ—¶é—´ç‚¹
FED_SCHEDULE_TIMES = ["08:31", "10:31", "15:01"]

# 2. å¸‚åœºå¹¿åº¦ (Market Breadth) æ—¶é—´ç‚¹ (æ”¶ç›˜å)
BREADTH_SCHEDULE_TIME = "16:30"

# 3. Reddit çƒ­åº¦æ¦œ æ—¶é—´ç‚¹ (ç›˜å‰)
REDDIT_SCHEDULE_TIME = "08:55"

# ------------------------------------------
# ğŸ¤– æœºå™¨äººä¿¡æ¯é…ç½®
# ------------------------------------------

# FedWatch Bot
ENABLE_FED_BOT = False  # å¦‚æœä¸éœ€è¦è·‘Fedï¼Œä¿æŒFalse
FED_BOT_NAME = "CME FedWatch Bot"
FED_BOT_AVATAR = "https://i.imgur.com/d8KLt6Z.png"

# å¸‚åœºå¹¿åº¦ Bot
BREADTH_BOT_NAME = "æ ‡æ™®500 å¹¿åº¦æ—¥æŠ¥" 
BREADTH_BOT_AVATAR = "https://i.imgur.com/Segc5PF.jpeg"

# Reddit çƒ­åº¦ Bot (æ–°)
REDDIT_BOT_NAME = "Stocksera èˆ†æƒ…çƒ­åº¦"
REDDIT_BOT_AVATAR = "https://i.imgur.com/8Qj5X9A.png" # è¿™é‡Œçš„å¤´åƒå¯ä»¥ä½¿ç”¨Reddit Logo

PREV_CUT_PROB = None

# ã€ä¿åº•ç­–ç•¥ã€‘ä¸‡ä¸€çˆ¬è™«æŠ“ä¸åˆ°æ—¥æœŸ/åˆ©ç‡
BACKUP_SCHEDULE = [
    "2025-12-10", "2026-01-28", "2026-03-18", "2026-05-06", 
    "2026-06-17", "2026-07-29", "2026-09-16", "2026-11-04", "2026-12-16"
]
DEFAULT_BACKUP_RATE = 3.50 

# ==========================================
# ğŸ› ï¸ è¾…åŠ©å‡½æ•°
# ==========================================

def parse_date_string(date_text):
    if not date_text: return None
    try:
        clean_text = re.sub(r'[^\w\s,]', '', date_text).strip()
        try:
            dt = datetime.strptime(clean_text, "%b %d, %Y")
            return dt.strftime("%Y-%m-%d")
        except: pass
        try:
            dt = datetime.strptime(clean_text, "%B %d, %Y")
            return dt.strftime("%Y-%m-%d")
        except: pass
        return None
    except:
        return None

def get_backup_meeting_date():
    tz = pytz.timezone('US/Eastern')
    today_str = datetime.now(tz).strftime("%Y-%m-%d")
    for meeting_date in BACKUP_SCHEDULE:
        if meeting_date >= today_str:
            return meeting_date
    return "TBD"

def is_market_holiday(now_et):
    if now_et.weekday() >= 5: return True, "å‘¨æœ«ä¼‘å¸‚"
    us_holidays = holidays.US(years=now_et.year) 
    if now_et.date() in us_holidays: return True, f"å‡æœŸ: {us_holidays.get(now_et.date())}"
    return False, None

def get_bar(p):
    length = 15
    filled = int(p / 100 * length)
    return "â–ˆ" * filled + "â–‘" * (length - filled)

def format_target_label(target_str, current_rate_base):
    try:
        lower_bound = float(target_str.split('-')[0].strip())
        if abs(lower_bound - current_rate_base) <= 0.05:
            return f"{target_str} (ç»´æŒ)"
        elif lower_bound < current_rate_base:
            return f"{target_str} (é™æ¯)"
        else:
            return f"{target_str} (åŠ æ¯)"
    except:
        return target_str

# ==========================================
# ğŸŸ¢ æ¨¡å— 1: é™æ¯æ¦‚ç‡ (FedWatch)
# ==========================================

def scrape_header_info(driver, page_text):
    rate = None
    meeting_date = None
    try:
        rate_match = re.search(r"Current.*?Rate.*?(\d+\.\d+)", page_text, re.IGNORECASE)
        if rate_match:
            val = float(rate_match.group(1))
            if 0.0 <= val <= 10.0: rate = val
    except: pass

    try:
        months = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]
        date_pattern = re.compile(r'(?:' + '|'.join(months) + r')\.?\s+\d{1,2},?\s+\d{4}', re.IGNORECASE)
        top_text = page_text[:2000]
        dates_found = date_pattern.findall(top_text)
        tz = pytz.timezone('US/Eastern')
        today = datetime.now(tz).date()

        for d_str in dates_found:
            parsed = parse_date_string(d_str)
            if parsed:
                p_date = datetime.strptime(parsed, "%Y-%m-%d").date()
                if p_date >= today:
                    meeting_date = parsed
                    break 
    except: pass
    return rate, meeting_date

def get_fed_data():
    if not ENABLE_FED_BOT:
        print("â¸ï¸ [ç³»ç»Ÿ] FedWatch Bot å·²ç¦ç”¨ï¼Œè·³è¿‡æŠ“å–...")
        return None

    print(f"âš¡ å¯åŠ¨ Chromium...")
    options = Options()
    options.binary_location = "/usr/bin/chromium" 
    options.add_argument("--headless=new") 
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)")

    driver = None
    result = {"current_base_rate": None, "next_meeting": None, "data": []}
      
    try:
        service = Service("/usr/bin/chromedriver") 
        driver = webdriver.Chrome(service=service, options=options)
        driver.set_page_load_timeout(60)
        driver.get("https://www.investing.com/central-banks/fed-rate-monitor")
        time.sleep(5) 
        
        page_text = driver.find_element(By.TAG_NAME, "body").text
        scraped_rate, scraped_date = scrape_header_info(driver, page_text)
        
        if scraped_rate: result["current_base_rate"] = scraped_rate
        else: result["current_base_rate"] = DEFAULT_BACKUP_RATE
            
        if scraped_date: result["next_meeting"] = scraped_date
        else: result["next_meeting"] = get_backup_meeting_date()

        data_points = []
        try:
            tables = driver.find_elements(By.TAG_NAME, "table")
            target_table = None
            for tbl in tables:
                if "%" in tbl.text and len(tbl.find_elements(By.TAG_NAME, "tr")) < 15:
                    target_table = tbl
                    break
            if not target_table and tables: target_table = tables[0]

            if target_table:
                rows = target_table.find_elements(By.TAG_NAME, "tr")
                for row in rows:
                    cols = row.find_elements(By.TAG_NAME, "td")
                    if len(cols) >= 2:
                        txt0, txt1 = cols[0].text.strip(), cols[1].text.strip()
                        try:
                            if "%" in txt0: prob, target = float(txt0.replace("%", "")), txt1
                            elif "%" in txt1: prob, target = float(txt1.replace("%", "")), txt0
                            else: continue
                            data_points.append({"prob": prob, "target": target})
                        except: continue
        except: pass

        if not data_points: return None
        result["data"] = data_points
        return result

    except Exception as e:
        print(f"âŒ Error: {e}")
        return None
    finally:
        if driver:
            try: driver.quit()
            except: pass

def send_fed_embed(data):
    global PREV_CUT_PROB
    if not data or not data['data']: return
    
    base_rate = data.get("current_base_rate")
    next_meeting_date = data.get("next_meeting")
    
    current_cut_prob = 0.0
    target_cut_lower = base_rate - 0.25
    
    cut_item = None
    rest_items = []
    
    for item in data['data']:
        try:
            lower = float(item['target'].split('-')[0].strip())
            if abs(lower - target_cut_lower) <= 0.05:
                cut_item = item
                current_cut_prob = item['prob']
            else:
                rest_items.append(item)
        except:
            rest_items.append(item)
    
    delta = 0.0
    if PREV_CUT_PROB is not None:
        delta = current_cut_prob - PREV_CUT_PROB
    PREV_CUT_PROB = current_cut_prob
    
    trend_title = "ğŸ“‰ é™æ¯è¶‹åŠ¿å˜åŠ¨"
    if not cut_item and current_cut_prob == 0: trend_text = "æ— é™æ¯é¢„æœŸ"
    elif delta > 0.1: trend_text = f"æ¦‚ç‡ä¸Šå‡ +{delta:.1f}% ğŸ”¥"
    elif delta < -0.1: trend_text = f"æ¦‚ç‡ä¸‹é™ {delta:.1f}% â„ï¸"
    else: trend_text = "ç¨³å®š"

    display_list = []
    if cut_item: display_list.append(cut_item)
    if rest_items:
        rest_items.sort(key=lambda x: x['prob'], reverse=True)
        display_list.append(rest_items[0])
    
    if not display_list:
        data['data'].sort(key=lambda x: x['prob'], reverse=True)
        display_list = data['data'][:2]

    all_sorted = sorted(data['data'], key=lambda x: x['prob'], reverse=True)
    top1_real = all_sorted[0]
    
    label1_raw = format_target_label(top1_real['target'], base_rate)
    if "(ç»´æŒ)" in label1_raw: consensus_short = "â¸ï¸ ç»´æŒåˆ©ç‡ (Hold)"
    elif "(é™æ¯)" in label1_raw: consensus_short = "ğŸ“‰ é™æ¯ (Cut)"
    else: consensus_short = "ğŸ“ˆ åŠ æ¯ (Hike)"

    desc_lines = [f"**ğŸ—“ï¸ ä¸‹æ¬¡ä¼šè®®:** `{next_meeting_date}`\n"]
    
    for item in display_list:
        label = format_target_label(item['target'], base_rate)
        desc_lines.append(f"**ç›®æ ‡: {label}**")
        desc_lines.append(f"`{get_bar(item['prob'])}` **{item['prob']}%**\n")
    
    desc_lines.append("\n------------------------")

    payload = {
        "username": FED_BOT_NAME,
        "avatar_url": FED_BOT_AVATAR,
        "embeds": [{
            "title": "ğŸ›ï¸ CME FedWatchâ„¢",
            "description": "\n".join(desc_lines),
            "color": 0x3498DB,
            "fields": [
                {"name": trend_title, "value": trend_text, "inline": True},
                {"name": "ğŸ’¡ åå°”è¡—å…±è¯†", "value": consensus_short, "inline": True},
                {"name": "ğŸ“Š å½“å‰åŸºå‡†åˆ©ç‡", "value": f"{base_rate}%", "inline": False}
            ],
            "footer": {"text": f"Updated at {datetime.now().strftime('%H:%M')} ET | Auto-Scraped"}
        }]
    }
    try: requests.post(WEBHOOK_URL, json=payload)
    except Exception as e: print(f"âŒ æ¨é€å¤±è´¥: {e}")

# ==========================================
# ğŸ”µ æ¨¡å— 2: å¸‚åœºå¹¿åº¦ (Market Breadth)
# ==========================================
def generate_breadth_chart(breadth_20_series, breadth_50_series):
    plt.style.use('dark_background')
    fig, ax = plt.subplots(figsize=(10, 5))
    
    ax.plot(breadth_20_series.index, breadth_20_series.values, color='#f1c40f', linewidth=2, label='Stocks > 20 Day SMA %')
    ax.plot(breadth_50_series.index, breadth_50_series.values, color='#e74c3c', linewidth=2, label='Stocks > 50 Day SMA %')
    ax.fill_between(breadth_20_series.index, breadth_20_series.values, alpha=0.1, color='#f1c40f')
    
    ax.axhline(y=80, color='#ff5252', linestyle='--', linewidth=1, alpha=0.8)
    ax.text(breadth_20_series.index[0], 81, 'Overbought (80%)', color='#ff5252', fontsize=8)
    ax.axhline(y=20, color='#448aff', linestyle='--', linewidth=1, alpha=0.8)
    ax.text(breadth_20_series.index[0], 21, 'Oversold (20%)', color='#448aff', fontsize=8)

    ax.set_xlim(left=breadth_20_series.index[0], right=breadth_20_series.index[-1])

    last_date = breadth_20_series.index[-1]
    last_val_20 = breadth_20_series.iloc[-1]
    last_val_50 = breadth_50_series.iloc[-1]

    ax.annotate(f'{last_val_20:.1f}%', 
                xy=(last_date, last_val_20), 
                xytext=(-10, 10), textcoords='offset points',
                color='#f1c40f', fontsize=11, fontweight='bold', 
                ha='right', bbox=dict(boxstyle="round,pad=0.3", fc="#2f3136", ec="#f1c40f", alpha=0.8))

    ax.annotate(f'{last_val_50:.1f}%', 
                xy=(last_date, last_val_50), 
                xytext=(-10, -20), textcoords='offset points',
                color='#e74c3c', fontsize=11, fontweight='bold', 
                ha='right', bbox=dict(boxstyle="round,pad=0.3", fc="#2f3136", ec="#e74c3c", alpha=0.8))

    ax.set_title('S&P 500 Market Breadth (20 & 50 Day SMA)', fontsize=12, color='white', pad=15)
    ax.set_ylim(0, 100)
    ax.grid(True, linestyle=':', alpha=0.3)
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
    plt.xticks(rotation=0)
    ax.legend(loc='upper left', frameon=True, facecolor='#2f3136', edgecolor='#2f3136', labelcolor='white')
    
    buf = io.BytesIO()
    plt.savefig(buf, format='png', bbox_inches='tight', dpi=100, facecolor='#2b2d31')
    buf.seek(0)
    plt.close('all') 
    return buf

def get_market_sentiment(p):
    if p > 80: return "ğŸ”¥ğŸ”¥ **æ·±åº¦ç«çƒ­**"
    if p > 60: return "ğŸ”¥ **ç«çƒ­**"      
    if p < 20: return "â„ï¸â„ï¸ **æ·±åº¦å¯’å†·**"
    if p < 40: return "â„ï¸ **å¯’å†·**"      
    return "ğŸƒ **ç¨³å®š**"     

def run_breadth_task():
    print("ğŸ“Š å¯åŠ¨å¸‚åœºå¹¿åº¦ç»Ÿè®¡...")
    data = None
    closes = None
    sma20_df = None
    sma50_df = None
    
    try:
        try:
            url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
            headers = {'User-Agent': 'Mozilla/5.0'}
            resp = requests.get(url, headers=headers, timeout=10)
            tables = pd.read_html(io.StringIO(resp.text))
            df_tickers = next((df for df in tables if 'Symbol' in df.columns), None)
            tickers = [t.replace('.', '-') for t in df_tickers['Symbol'].tolist()] 
        except:
            tickers = ['AAPL', 'MSFT', 'NVDA', 'AMZN', 'GOOGL', 'META', 'TSLA', 'BRK-B', 'LLY', 'AVGO']

        warnings.simplefilter(action='ignore', category=FutureWarning)
        try:
            if os.path.exists('yfinance.cache'): shutil.rmtree('yfinance.cache')
        except: pass

        data = yf.download(tickers, period="2y", progress=False) 
        if 'Close' in data.columns: closes = data['Close']
        else: closes = data
        sma20_df = closes.rolling(window=20).mean()
        sma50_df = closes.rolling(window=50).mean()
        
        daily_breadth_20 = ((closes > sma20_df).sum(axis=1) / closes.notna().sum(axis=1)) * 100
        daily_breadth_50 = ((closes > sma50_df).sum(axis=1) / closes.notna().sum(axis=1)) * 100
        
        chart_buffer = generate_breadth_chart(daily_breadth_20.tail(252), daily_breadth_50.tail(252))
        current_p20 = daily_breadth_20.iloc[-1]
        current_p50 = daily_breadth_50.iloc[-1]
        
        sentiment_20 = get_market_sentiment(current_p20)
        sentiment_50 = get_market_sentiment(current_p50)

        payload_data = {
            "username": BREADTH_BOT_NAME,
            "avatar_url": BREADTH_BOT_AVATAR,
            "embeds": [{
                "title": "S&P 500 å¸‚åœºå¹¿åº¦",
                "description": f"**æ—¥æœŸ:** `{datetime.now().strftime('%Y-%m-%d')}`\n\n"
                               f"**è‚¡ä»· > 20æ—¥å‡çº¿:** **{current_p20:.1f}%**\n"
                               f"{sentiment_20}\n\n"
                               f"**è‚¡ä»· > 50æ—¥å‡çº¿:** **{current_p50:.1f}%**\n"
                               f"{sentiment_50}",
                "color": 0xF1C40F,
                "image": {"url": "attachment://chart.png"},
                "footer": {
                    "text": f"ğŸ’¡ æ ‡æ™®500å¤§äº20æ—¥ã€50æ—¥å‡çš„æ•°é‡\nğŸ’¡ >80% è­¦æƒ•å›è°ƒï¼Œ<20% å­•è‚²åå¼¹ã€‚\nï¼ˆç»Ÿè®¡æ ·æœ¬: {len(tickers)}åªæˆåˆ†è‚¡ï¼‰"
                }
            }]
        }
        
        files = {'file': ('chart.png', chart_buffer, 'image/png')}
        requests.post(WEBHOOK_URL, data={'payload_json': json.dumps(payload_data)}, files=files)
        
        chart_buffer.close()
        print(f"âœ… å¹¿åº¦æŠ¥å‘Šå·²æ¨é€")

    except Exception as e:
        print(f"âŒ å¹¿åº¦ä»»åŠ¡å¼‚å¸¸: {e}")
    
    finally:
        print("ğŸ§¹ æ­£åœ¨æ¸…ç†å†…å­˜...")
        try:
            del data
            del closes
            del sma20_df
            del sma50_df
        except: pass
        gc.collect()

# ==========================================
# ğŸ”´ æ¨¡å— 3: Stocksera Reddit çƒ­åº¦æ¦œ (æ–°å¢)
# ==========================================

def get_stocksera_reddit():
    """
    è·å–Stockseraçš„Redditçƒ­åº¦æ•°æ®
    """
    print("ğŸ“¡ æ­£åœ¨è·å– Stocksera Reddit æ•°æ®...")
    # Stocksera å®˜æ–¹æ¥å£ (è·å–24å°æ—¶å†…çš„æåŠæ¬¡æ•°)
    url = "https://stocksera.pythonanywhere.com/api/reddit_mentions"
    
    try:
        # æ·»åŠ  User-Agent é˜²æ­¢è¢«æ‹’
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        response = requests.get(url, headers=headers, timeout=20)
        
        if response.status_code == 200:
            data = response.json()
            # Stocksera è¿”å›çš„æ˜¯æ•´ä¸ªåˆ—è¡¨ï¼Œæˆ‘ä»¬éœ€è¦æŒ‰æåŠæ¬¡æ•°(mentions)æ’åº
            # æ ¼å¼é€šå¸¸æ˜¯: [{'symbol': 'AAPL', 'name': 'Apple Inc.', 'mentions': 100, ...}, ...]
            
            # è¿‡æ»¤æ‰ mention ä¸º 0 çš„
            filtered_data = [d for d in data if d.get('mentions', 0) > 0]
            
            # æŒ‰ mentions é™åºæ’åˆ— (é˜²ä¸‡ä¸€APIæœªæ’åº)
            sorted_data = sorted(filtered_data, key=lambda x: x.get('mentions', 0), reverse=True)
            
            # å–å‰20å
            return sorted_data[:20]
        else:
            print(f"âš ï¸ Stocksera API è¿”å›é”™è¯¯: {response.status_code}")
            return None
    except Exception as e:
        print(f"âŒ è·å– Reddit æ•°æ®å¤±è´¥: {e}")
        return None

def run_reddit_task():
    data = get_stocksera_reddit()
    if not data:
        return

    # æ„å»º Embed Description
    # æ ¼å¼: 1. $AAPL (Apple Inc.) - æåŠ: 123
    desc_lines = []
    
    for i, item in enumerate(data):
        rank = i + 1
        symbol = item.get('symbol', 'Unknown')
        name = item.get('name', '')
        count = item.get('mentions', 0)
        
        # ç®€å•çš„çƒ­åº¦å›¾æ ‡
        fire = ""
        if i < 3: fire = "ğŸ”¥"
        
        # å¤„ç†è¶…é•¿å…¬å¸åï¼Œæˆªæ–­ä¸€ä¸‹ä¿æŒç¾è§‚
        if len(name) > 20:
            name = name[:20] + "..."
            
        line = f"**{rank}. ${symbol}** ({name}) `{count}æ¬¡` {fire}"
        desc_lines.append(line)

    # ç»„åˆæˆ Embed
    payload = {
        "username": REDDIT_BOT_NAME,
        "avatar_url": REDDIT_BOT_AVATAR,
        "embeds": [{
            "title": "ğŸš€ Reddit 24H çƒ­é—¨è‚¡ç¥¨æ¦œ (Top 20)",
            "description": "\n".join(desc_lines),
            "color": 0xFF4500, # Reddit Orange
            "footer": {
                "text": f"æ•°æ®æ¥æº: Stocksera | {datetime.now().strftime('%Y-%m-%d %H:%M')} ET\næ³¨: ç»Ÿè®¡èŒƒå›´åŒ…æ‹¬ r/wallstreetbets, r/stocks ç­‰"
            }
        }]
    }
    
    try:
        requests.post(WEBHOOK_URL, json=payload)
        print("âœ… Reddit çƒ­åº¦æ¦œå·²æ¨é€")
    except Exception as e:
        print(f"âŒ Reddit æ¨é€å¤±è´¥: {e}")
        
    # åƒåœ¾å›æ”¶
    gc.collect()

# ==========================================
# ğŸš€ ä¸»ç¨‹åº
# ==========================================
if __name__ == "__main__":
    print("ğŸš€ ç›‘æ§æœåŠ¡å·²å¯åŠ¨")
    
    # --- å¯åŠ¨è‡ªæ£€ (æµ‹è¯•æ¨¡å¼) ---
    print("-------------- ç³»ç»Ÿè‡ªæ£€ --------------")
    
    if ENABLE_FED_BOT:
        print("ğŸ§ª [æµ‹è¯•] FedWatch...")
        fed_data = get_fed_data()
        if fed_data: send_fed_embed(fed_data)
    else:
        print("â¸ï¸ [æµ‹è¯•] FedWatch å·²ç¦ç”¨")

    print("ğŸ§ª [æµ‹è¯•] å¸‚åœºå¹¿åº¦...")
    run_breadth_task()
    
    print("ğŸ§ª [æµ‹è¯•] Reddit çƒ­åº¦æ¦œ...")
    run_reddit_task()
    
    print("âœ… è‡ªæ£€ç»“æŸï¼Œè¿›å…¥å®šæ—¶ç›‘å¬æ¨¡å¼...")
    print("--------------------------------------")

    last_run_time_str = ""
    
    while True:
        try:
            tz = pytz.timezone('US/Eastern')
            now_et = datetime.now(tz)
            current_str = now_et.strftime("%H:%M")
            is_holiday, holiday_name = is_market_holiday(now_et)

            if current_str != last_run_time_str:
                print(f"â° {current_str} ET (Market Open: {not is_holiday})")
                
                # åªæœ‰åœ¨éå‡æœŸ/éå‘¨æœ«æ—¶æ‰æ¨é€
                if not is_holiday:
                    # 1. FedWatch
                    if current_str in FED_SCHEDULE_TIMES:
                        if ENABLE_FED_BOT:
                            print(f"ğŸ”” è§¦å‘ FedWatch: {current_str}")
                            data = get_fed_data()
                            if data: send_fed_embed(data)
                        else:
                            print(f"â¸ï¸ æ—¶é—´åˆ°ï¼Œä½† FedBot ç¦ç”¨")
                    
                    # 2. Market Breadth
                    if current_str == BREADTH_SCHEDULE_TIME:
                        print(f"ğŸ”” è§¦å‘ å¸‚åœºå¹¿åº¦: {current_str}")
                        run_breadth_task()
                        
                    # 3. Reddit Trending (æ–°å¢)
                    if current_str == REDDIT_SCHEDULE_TIME:
                        print(f"ğŸ”” è§¦å‘ Reddit çƒ­åº¦æ¦œ: {current_str}")
                        run_reddit_task()
                        
                else:
                    # å‡æœŸ/å‘¨æœ«æ—¶ï¼Œåªæ‰“å°å¿ƒè·³
                    all_times = FED_SCHEDULE_TIMES + [BREADTH_SCHEDULE_TIME, REDDIT_SCHEDULE_TIME]
                    if current_str in all_times:
                        print(f"ğŸ˜´ ä»Šæ—¥ä¼‘å¸‚ ({holiday_name})ï¼Œè·³è¿‡æ¨é€")

                last_run_time_str = current_str
        
        except Exception as e:
            print(f"âš ï¸ ä¸»å¾ªç¯æŠ¥é”™: {e}")
            time.sleep(5)
            
        time.sleep(30)
